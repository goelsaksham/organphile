{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Stacking Model\n",
    "\n",
    "This notebook is used to train a CNN model for All class classification on top of the stacking images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n",
    "\n",
    "This section will import the required libaries that will be used to actually implement the training for the Vanilla RNN Binary Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, BatchNormalization, Flatten, Dense\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding this so that can use the python scripts for loading the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the python script training data loader function. This function loads the data from the *.wav* files directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_scripts.directory_funcs import *\n",
    "from py_scripts.wav_file_funcs import *\n",
    "from py_scripts.misc_audio_signal_funcs import *\n",
    "from py_scripts.raw_training_data_creation import load_irmas_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Training Data\n",
    "\n",
    "This section defines the training data generators the script from the training data creation module to load the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cel', 'cla', 'flu', 'gac', 'gel', 'org', 'pia', 'sax', 'tru', 'vio', 'voi']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First define the training data directory, and find the different classes that exist\n",
    "training_data_dir = '../../data/images_jpg/train/'\n",
    "validation_data_dir = '../../data/images_jpg/validation/'\n",
    "test_data_dir = '../../data/images_jpg/test/'\n",
    "get_subdirectory_names(training_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the generators for each category (Train, Validation, Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4736 images belonging to 5 classes.\n",
      "Found 1013 images belonging to 5 classes.\n",
      "Found 1013 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('../../data/images_jpg/train/', target_size=(150, 150),\n",
    "                                                    batch_size=64, class_mode='categorical')\n",
    "validaton_generator = validation_datagen.flow_from_directory('../../data/images_jpg/validation/', target_size=(150, 150),\n",
    "                                                             batch_size=64, class_mode='categorical')\n",
    "test_generator = test_datagen.flow_from_directory('../../data/images_jpg/test/', target_size=(150, 150),\n",
    "                                                  batch_size=64, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Model\n",
    "\n",
    "In this section, we define the CNN model for the stacked images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 73, 73, 16)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 36, 36, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 32, 32, 32)        12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 12, 12, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 5765      \n",
      "=================================================================\n",
      "Total params: 45,445\n",
      "Trainable params: 45,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (5, 5), strides=(2, 2), activation='relu', input_shape = (150, 150, 3)))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Conv2D(32, (5, 5), strides = (1, 1), activation='relu'))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Conv2D(32, (5, 5), strides = (1, 1), activation='relu'))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(5, activation = 'softmax'))\n",
    "# Compiling the model\n",
    "model.compile(loss= 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a checkpoint\n",
    "parent_weight_save_dir = '../../data/Training Results/CNN_Stacking/Weights'\n",
    "tensor_board_dir_path = '../../data/Training Results/CNN_Stacking/TensorBoard'\n",
    "check_output_directory(parent_weight_save_dir)\n",
    "current_experiment_name = f'CT-{time.time()}'\n",
    "weight_file_path = os.path.join(parent_weight_save_dir, f'{current_experiment_name}.hdf5')\n",
    "tensor_board_file_path = os.path.join(tensor_board_dir_path, current_experiment_name)\n",
    "check_output_directory(tensor_board_file_path)\n",
    "checkpoint = ModelCheckpoint(weight_file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "tensorboard = TensorBoard(log_dir=tensor_board_file_path)\n",
    "early_stopping_criteria = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "callbacks_list = [tensorboard, checkpoint, early_stopping_criteria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "74/74 [==============================] - 191s 3s/step - loss: 1.5049 - acc: 0.3332 - val_loss: 1.4183 - val_acc: 0.3771\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.37710, saving model to ../../data/Training Results/CNN_Stacking/Weights\\CT-1544941011.688695.hdf5\n",
      "Epoch 2/50\n",
      "74/74 [==============================] - 139s 2s/step - loss: 1.4292 - acc: 0.3670 - val_loss: 1.3552 - val_acc: 0.3988\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.37710 to 0.39882, saving model to ../../data/Training Results/CNN_Stacking/Weights\\CT-1544941011.688695.hdf5\n",
      "Epoch 3/50\n",
      "74/74 [==============================] - 139s 2s/step - loss: 1.3838 - acc: 0.3999 - val_loss: 1.4133 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.39882\n",
      "Epoch 4/50\n",
      "74/74 [==============================] - 134s 2s/step - loss: 1.3446 - acc: 0.4088 - val_loss: 1.3307 - val_acc: 0.4235\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.39882 to 0.42349, saving model to ../../data/Training Results/CNN_Stacking/Weights\\CT-1544941011.688695.hdf5\n",
      "Epoch 5/50\n",
      "74/74 [==============================] - 173s 2s/step - loss: 1.3428 - acc: 0.4234 - val_loss: 1.3166 - val_acc: 0.4393\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.42349 to 0.43929, saving model to ../../data/Training Results/CNN_Stacking/Weights\\CT-1544941011.688695.hdf5\n",
      "Epoch 6/50\n",
      "74/74 [==============================] - 162s 2s/step - loss: 1.3279 - acc: 0.4261 - val_loss: 1.3902 - val_acc: 0.4166\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.43929\n",
      "Epoch 7/50\n",
      "31/74 [===========>..................] - ETA: 1:16 - loss: 1.3134 - acc: 0.4360"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator, epochs=50, validation_data=validaton_generator, callbacks=callbacks_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
