{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM RNN Model\n",
    "\n",
    "This notebook is used to train a LSTM RNN model for All class classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n",
    "\n",
    "This section will import the required libaries that will be used to actually implement the training for the Vanilla RNN Binary Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Input\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding this so that can use the python scripts for loading the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the python script training data loader function. This function loads the data from the *.wav* files directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_scripts.directory_funcs import *\n",
    "from py_scripts.wav_file_funcs import *\n",
    "from py_scripts.misc_audio_signal_funcs import *\n",
    "from py_scripts.raw_training_data_creation import load_irmas_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Training Data\n",
    "\n",
    "This section uses the script from the training data creation module to load the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cel', 'cla', 'flu', 'gac', 'gel', 'org', 'pia', 'sax', 'tru', 'vio', 'voi']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First define the training data directory, and find the different classes that exist\n",
    "training_data_dir = '../../data/whole_dataset/training/'\n",
    "get_subdirectory_names(training_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classes that we will work\n",
    "all_classes = get_subdirectory_names(training_data_dir)\n",
    "# Defining the classes that will be the ones on which we will train for the project\n",
    "classes_for_project = ['gel', 'pia', 'sax', 'vio', 'voi']\n",
    "mapping_to_index = dict(zip(classes_for_project, range(len(classes_for_project))))\n",
    "# Getting the frequency for each class\n",
    "class_num_files = dict(zip(classes_for_project, [len(get_file_names(construct_path(training_data_dir, class_name), '*.wav')) for class_name in classes_for_project]))\n",
    "# Defining the class which will be used as the one v/s all classifier to denote all other classes except the current class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Data from gel\n",
      "Processing: 250 files\n",
      "Loaded all the data from the class\n",
      "Getting Data from pia\n",
      "Processing: 250 files\n",
      "Loaded all the data from the class\n",
      "Getting Data from sax\n",
      "Processing: 250 files\n",
      "Loaded all the data from the class\n",
      "Getting Data from vio\n",
      "Processing: 250 files\n",
      "Loaded all the data from the class\n",
      "Getting Data from voi\n",
      "Processing: 250 files\n",
      "Loaded all the data from the class\n"
     ]
    }
   ],
   "source": [
    "# Defining the various parameters for loading the input data\n",
    "rnn_window = (300, 300) # in the format of length of vector and the shift\n",
    "class_num_examples = 250\n",
    "X, y = load_irmas_data(training_data_dir, classes_for_project, rnn_window, number_of_training_examples_per_class=class_num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 294, 300), (5000,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying the shape\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing a train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeing up previous memory\n",
    "X = None\n",
    "y = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Training Samples: (4000,)\n",
      "Total number of timestamp values for each sample: 294\n",
      "Total number of features for each sample: 300\n"
     ]
    }
   ],
   "source": [
    "print(f'Total Number of Training Samples: {y_train.shape}')\n",
    "print(f'Total number of timestamp values for each sample: {X_train.shape[1]}')\n",
    "print(f'Total number of features for each sample: {X_train.shape[-1]}')\n",
    "#print(f'Minimum Feature Value: {np.min(X_train)}, Maximum Feature Value: {np.max(X_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Testing Samples: (1000,)\n",
      "Total number of timestamp values for each sample: 294\n",
      "Total number of features for each sample: 300\n"
     ]
    }
   ],
   "source": [
    "print(f'Total Number of Testing Samples: {y_test.shape}')\n",
    "print(f'Total number of timestamp values for each sample: {X_test.shape[1]}')\n",
    "print(f'Total number of features for each sample: {X_test.shape[-1]}')\n",
    "#print(f'Minimum Feature Value: {np.min(X_train)}, Maximum Feature Value: {np.max(X_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gel', 'pia', 'sax', 'vio', 'voi'], dtype='object') Index(['gel', 'pia', 'sax', 'vio', 'voi'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "y_train_categorical = pd.Categorical(y_train)\n",
    "y_train_numerical = y_train_categorical.codes\n",
    "y_test_categorical = pd.Categorical(y_test)\n",
    "y_test_numerical = y_test_categorical.codes\n",
    "# Checking the categries\n",
    "print(y_train_categorical.categories, y_test_categorical.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of categories\n",
    "len(y_train_categorical.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If training for more than 1 class then need to convert to categorical\n",
    "if len(y_train_categorical.categories) > 2:\n",
    "    y_train_numerical = to_categorical(y_train_numerical)\n",
    "    y_test_numerical = to_categorical(y_test_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_numerical.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check For Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('X_train', 1411200128),\n",
       " ('X_test', 352800128),\n",
       " ('y_train', 48096),\n",
       " ('y_test', 12096),\n",
       " ('y_train_categorical', 4484),\n",
       " ('y_test_categorical', 1484),\n",
       " ('Dense', 1056),\n",
       " ('EarlyStopping', 1056),\n",
       " ('Embedding', 1056),\n",
       " ('LSTM', 1056),\n",
       " ('ModelCheckpoint', 1056),\n",
       " ('Sequential', 1056),\n",
       " ('TensorBoard', 1056),\n",
       " ('nb_dir', 285),\n",
       " ('class_num_files', 240),\n",
       " ('mapping_to_index', 240),\n",
       " ('all_classes', 160),\n",
       " ('training_data_dir', 153),\n",
       " ('Input', 136),\n",
       " ('check_output_directory', 136),\n",
       " ('construct_path', 136),\n",
       " ('exist_directory', 136),\n",
       " ('exist_file', 136),\n",
       " ('get_directory_contents', 136),\n",
       " ('get_file_names', 136),\n",
       " ('get_left_channel_data', 136),\n",
       " ('get_right_channel_data', 136),\n",
       " ('get_sound_signals', 136),\n",
       " ('get_subdirectory_names', 136),\n",
       " ('load_irmas_data', 136),\n",
       " ('normalize_sound_signals', 136),\n",
       " ('read_wav_file', 136),\n",
       " ('shift_sound_signals', 136),\n",
       " ('to_categorical', 136),\n",
       " ('train_test_split', 136),\n",
       " ('y_test_numerical', 112),\n",
       " ('y_train_numerical', 112),\n",
       " ('classes_for_project', 104),\n",
       " ('np', 80),\n",
       " ('pd', 80),\n",
       " ('sequence', 80),\n",
       " ('wavfile', 80),\n",
       " ('rnn_window', 64),\n",
       " ('class_num_examples', 28),\n",
       " ('X', 16),\n",
       " ('y', 16)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "This section will define the model architecture that will be used for the training purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features (Feature Vector Length): 300, Number of Time Stamps: 294\n"
     ]
    }
   ],
   "source": [
    "# Defining the parameters for the Embedding layer\n",
    "number_of_features = X_train.shape[-1]\n",
    "number_of_time_stamps = X_train.shape[1]\n",
    "print(f'Number of Features (Feature Vector Length): {number_of_features}, Number of Time Stamps: {number_of_time_stamps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 50)                70200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 70,455\n",
      "Trainable params: 70,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "rnn_layer_num_units = 50\n",
    "num_classes_for_training = len(y_train_categorical.categories)\n",
    "model = Sequential()\n",
    "model.add(LSTM(rnn_layer_num_units, input_shape=(number_of_time_stamps, number_of_features), dropout = 0.1))\n",
    "model.add(Dense(num_classes_for_training, activation='softmax'))\n",
    "# Compiling the model\n",
    "model.compile(loss= 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a checkpoint\n",
    "parent_weight_save_dir = '../../data/Training Results/LSTM/Weights'\n",
    "tensor_board_dir_path = '../../data/Training Results/LSTM/TensorBoard'\n",
    "check_output_directory(parent_weight_save_dir)\n",
    "current_experiment_name = f'AllClasses_InputVectorLen-{number_of_features}_TimeStamps-{number_of_time_stamps}_CT-{time.time()}'\n",
    "weight_file_path = os.path.join(parent_weight_save_dir, f'{current_experiment_name}.hdf5')\n",
    "tensor_board_file_path = os.path.join(tensor_board_dir_path, current_experiment_name)\n",
    "check_output_directory(tensor_board_file_path)\n",
    "checkpoint = ModelCheckpoint(weight_file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "tensorboard = TensorBoard(log_dir=tensor_board_file_path)\n",
    "early_stopping_criteria = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "callbacks_list = [tensorboard, checkpoint, early_stopping_criteria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/50\n",
      "3200/3200 [==============================] - 47s 15ms/step - loss: 1.4909 - acc: 0.3244 - val_loss: 1.3195 - val_acc: 0.3425\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.34250, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544161635.9100685.hdf5\n",
      "Epoch 2/50\n",
      "3200/3200 [==============================] - 47s 15ms/step - loss: 1.2641 - acc: 0.4041 - val_loss: 1.2767 - val_acc: 0.3588\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.34250 to 0.35875, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544161635.9100685.hdf5\n",
      "Epoch 3/50\n",
      "3200/3200 [==============================] - 42s 13ms/step - loss: 1.2277 - acc: 0.4206 - val_loss: 1.2653 - val_acc: 0.3738\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.35875 to 0.37375, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544161635.9100685.hdf5\n",
      "Epoch 4/50\n",
      "3200/3200 [==============================] - 51s 16ms/step - loss: 1.2172 - acc: 0.4441 - val_loss: 1.2693 - val_acc: 0.3987\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.37375 to 0.39875, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544161635.9100685.hdf5\n",
      "Epoch 5/50\n",
      "3200/3200 [==============================] - 40s 13ms/step - loss: 1.1908 - acc: 0.4509 - val_loss: 1.2581 - val_acc: 0.3900\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.39875\n",
      "Epoch 6/50\n",
      "3200/3200 [==============================] - 42s 13ms/step - loss: 1.2105 - acc: 0.4450 - val_loss: 1.3142 - val_acc: 0.3438\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.39875\n",
      "Epoch 7/50\n",
      "3200/3200 [==============================] - 42s 13ms/step - loss: 1.1805 - acc: 0.4709 - val_loss: 1.2443 - val_acc: 0.4000\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.39875 to 0.40000, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544161635.9100685.hdf5\n",
      "Epoch 8/50\n",
      "3200/3200 [==============================] - 54s 17ms/step - loss: 1.1488 - acc: 0.4859 - val_loss: 1.2435 - val_acc: 0.4088\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.40000 to 0.40875, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544161635.9100685.hdf5\n",
      "Epoch 9/50\n",
      "3200/3200 [==============================] - 54s 17ms/step - loss: 1.1514 - acc: 0.4900 - val_loss: 1.2335 - val_acc: 0.4200\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.40875 to 0.42000, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544161635.9100685.hdf5\n",
      "Epoch 10/50\n",
      "3200/3200 [==============================] - 48s 15ms/step - loss: 1.1143 - acc: 0.5116 - val_loss: 1.2234 - val_acc: 0.4213\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.42000 to 0.42125, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544161635.9100685.hdf5\n",
      "Epoch 11/50\n",
      "3200/3200 [==============================] - 46s 14ms/step - loss: 1.0990 - acc: 0.5144 - val_loss: 1.2196 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.42125 to 0.43750, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544161635.9100685.hdf5\n",
      "Epoch 12/50\n",
      "3200/3200 [==============================] - 48s 15ms/step - loss: 1.0870 - acc: 0.5353 - val_loss: 1.2260 - val_acc: 0.4425\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.43750 to 0.44250, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544161635.9100685.hdf5\n",
      "Epoch 13/50\n",
      "3200/3200 [==============================] - 47s 15ms/step - loss: 1.0628 - acc: 0.5363 - val_loss: 1.2453 - val_acc: 0.4313\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.44250\n",
      "Epoch 14/50\n",
      "3200/3200 [==============================] - 59s 18ms/step - loss: 1.0450 - acc: 0.5434 - val_loss: 1.2224 - val_acc: 0.4363\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.44250\n",
      "Epoch 15/50\n",
      "3200/3200 [==============================] - 47s 15ms/step - loss: 1.0294 - acc: 0.5622 - val_loss: 1.2236 - val_acc: 0.4487\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.44250 to 0.44875, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544161635.9100685.hdf5\n",
      "Epoch 16/50\n",
      "3200/3200 [==============================] - 42s 13ms/step - loss: 1.0132 - acc: 0.5628 - val_loss: 1.2643 - val_acc: 0.4350\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.44875\n",
      "Epoch 17/50\n",
      "3200/3200 [==============================] - 48s 15ms/step - loss: 0.9812 - acc: 0.5847 - val_loss: 1.2342 - val_acc: 0.4462\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.44875\n",
      "Epoch 18/50\n",
      "3200/3200 [==============================] - 50s 15ms/step - loss: 0.9742 - acc: 0.5837 - val_loss: 1.2266 - val_acc: 0.4363\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.44875\n",
      "Epoch 19/50\n",
      "3200/3200 [==============================] - 46s 14ms/step - loss: 0.9640 - acc: 0.5825 - val_loss: 1.2258 - val_acc: 0.4537\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.44875 to 0.45375, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544161635.9100685.hdf5\n",
      "Epoch 20/50\n",
      "3200/3200 [==============================] - 46s 14ms/step - loss: 0.9335 - acc: 0.5984 - val_loss: 1.2456 - val_acc: 0.4587\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.45375 to 0.45875, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544161635.9100685.hdf5\n",
      "Epoch 21/50\n",
      "3200/3200 [==============================] - 50s 16ms/step - loss: 0.9189 - acc: 0.6125 - val_loss: 1.2542 - val_acc: 0.4662\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.45875 to 0.46625, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544161635.9100685.hdf5\n",
      "Epoch 22/50\n",
      "3200/3200 [==============================] - 47s 15ms/step - loss: 0.8952 - acc: 0.6222 - val_loss: 1.2428 - val_acc: 0.4500\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.46625\n",
      "Epoch 23/50\n",
      "3200/3200 [==============================] - 54s 17ms/step - loss: 0.8822 - acc: 0.6247 - val_loss: 1.2475 - val_acc: 0.4562\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.46625\n",
      "Epoch 24/50\n",
      "3200/3200 [==============================] - 44s 14ms/step - loss: 0.8606 - acc: 0.6384 - val_loss: 1.3375 - val_acc: 0.4525\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.46625\n",
      "Epoch 25/50\n",
      "3200/3200 [==============================] - 54s 17ms/step - loss: 0.8904 - acc: 0.6162 - val_loss: 1.2981 - val_acc: 0.4387\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.46625\n",
      "Epoch 26/50\n",
      "3200/3200 [==============================] - 55s 17ms/step - loss: 0.8665 - acc: 0.6325 - val_loss: 1.2941 - val_acc: 0.4525\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.46625\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train_numerical, epochs=50, batch_size=64, validation_split=0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 3s 3ms/step\n",
      "Accuracy: 47.10%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test_numerical, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 160,905\n",
      "Trainable params: 160,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "rnn_layer_num_units = 100\n",
    "num_classes_for_training = len(y_train_categorical.categories)\n",
    "model = Sequential()\n",
    "model.add(LSTM(rnn_layer_num_units, input_shape=(number_of_time_stamps, number_of_features), dropout = 0.1))\n",
    "model.add(Dense(num_classes_for_training, activation='softmax'))\n",
    "# Compiling the model\n",
    "model.compile(loss= 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a checkpoint\n",
    "parent_weight_save_dir = '../../data/Training Results/LSTM/Weights'\n",
    "tensor_board_dir_path = '../../data/Training Results/LSTM/TensorBoard'\n",
    "check_output_directory(parent_weight_save_dir)\n",
    "current_experiment_name = f'AllClasses_InputVectorLen-{number_of_features}_TimeStamps-{number_of_time_stamps}_CT-{time.time()}'\n",
    "weight_file_path = os.path.join(parent_weight_save_dir, f'{current_experiment_name}.hdf5')\n",
    "tensor_board_file_path = os.path.join(tensor_board_dir_path, current_experiment_name)\n",
    "check_output_directory(tensor_board_file_path)\n",
    "checkpoint = ModelCheckpoint(weight_file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "tensorboard = TensorBoard(log_dir=tensor_board_file_path)\n",
    "early_stopping_criteria = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "callbacks_list = [tensorboard, checkpoint, early_stopping_criteria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/50\n",
      "3200/3200 [==============================] - 50s 15ms/step - loss: 1.4756 - acc: 0.3091 - val_loss: 1.3206 - val_acc: 0.3638\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.36375, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544163216.7849946.hdf5\n",
      "Epoch 2/50\n",
      "3200/3200 [==============================] - 51s 16ms/step - loss: 1.2614 - acc: 0.4034 - val_loss: 1.2702 - val_acc: 0.3738\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.36375 to 0.37375, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544163216.7849946.hdf5\n",
      "Epoch 3/50\n",
      "3200/3200 [==============================] - 70s 22ms/step - loss: 1.2316 - acc: 0.4275 - val_loss: 1.2891 - val_acc: 0.3787\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.37375 to 0.37875, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544163216.7849946.hdf5\n",
      "Epoch 4/50\n",
      "3200/3200 [==============================] - 71s 22ms/step - loss: 1.2274 - acc: 0.4094 - val_loss: 1.2667 - val_acc: 0.3800\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.37875 to 0.38000, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544163216.7849946.hdf5\n",
      "Epoch 5/50\n",
      "3200/3200 [==============================] - 60s 19ms/step - loss: 1.1911 - acc: 0.4506 - val_loss: 1.2568 - val_acc: 0.3925\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.38000 to 0.39250, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544163216.7849946.hdf5\n",
      "Epoch 6/50\n",
      "3200/3200 [==============================] - 65s 20ms/step - loss: 1.1644 - acc: 0.4616 - val_loss: 1.2695 - val_acc: 0.3825\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.39250\n",
      "Epoch 7/50\n",
      "3200/3200 [==============================] - 64s 20ms/step - loss: 1.1290 - acc: 0.4888 - val_loss: 1.2318 - val_acc: 0.4125\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.39250 to 0.41250, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544163216.7849946.hdf5\n",
      "Epoch 8/50\n",
      "3200/3200 [==============================] - 60s 19ms/step - loss: 1.1309 - acc: 0.4725 - val_loss: 1.5391 - val_acc: 0.2400\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.41250\n",
      "Epoch 9/50\n",
      "3200/3200 [==============================] - 68s 21ms/step - loss: 1.3047 - acc: 0.4213 - val_loss: 1.3973 - val_acc: 0.4037\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.41250\n",
      "Epoch 10/50\n",
      "3200/3200 [==============================] - 58s 18ms/step - loss: 1.1623 - acc: 0.4984 - val_loss: 1.2585 - val_acc: 0.4088\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.41250\n",
      "Epoch 11/50\n",
      "3200/3200 [==============================] - 57s 18ms/step - loss: 1.0817 - acc: 0.5225 - val_loss: 1.2403 - val_acc: 0.4113\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.41250\n",
      "Epoch 12/50\n",
      "3200/3200 [==============================] - 58s 18ms/step - loss: 1.0394 - acc: 0.5394 - val_loss: 1.2378 - val_acc: 0.4263\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.41250 to 0.42625, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544163216.7849946.hdf5\n",
      "Epoch 13/50\n",
      "3200/3200 [==============================] - 62s 19ms/step - loss: 1.0073 - acc: 0.5619 - val_loss: 1.2534 - val_acc: 0.4363\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.42625 to 0.43625, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544163216.7849946.hdf5\n",
      "Epoch 14/50\n",
      "3200/3200 [==============================] - 60s 19ms/step - loss: 0.9757 - acc: 0.5747 - val_loss: 1.2339 - val_acc: 0.4300\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.43625\n",
      "Epoch 15/50\n",
      "3200/3200 [==============================] - 57s 18ms/step - loss: 0.9312 - acc: 0.5966 - val_loss: 1.2572 - val_acc: 0.4350\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.43625\n",
      "Epoch 16/50\n",
      "3200/3200 [==============================] - 57s 18ms/step - loss: 0.9180 - acc: 0.6062 - val_loss: 1.2269 - val_acc: 0.4500\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.43625 to 0.45000, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544163216.7849946.hdf5\n",
      "Epoch 17/50\n",
      "3200/3200 [==============================] - 57s 18ms/step - loss: 0.8904 - acc: 0.6106 - val_loss: 1.2639 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.45000\n",
      "Epoch 18/50\n",
      "3200/3200 [==============================] - 58s 18ms/step - loss: 0.8612 - acc: 0.6281 - val_loss: 1.2384 - val_acc: 0.4587\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.45000 to 0.45875, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544163216.7849946.hdf5\n",
      "Epoch 19/50\n",
      "3200/3200 [==============================] - 58s 18ms/step - loss: 0.8305 - acc: 0.6425 - val_loss: 1.2417 - val_acc: 0.4725\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.45875 to 0.47250, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544163216.7849946.hdf5\n",
      "Epoch 20/50\n",
      "3200/3200 [==============================] - 57s 18ms/step - loss: 0.8462 - acc: 0.6366 - val_loss: 1.2739 - val_acc: 0.4363\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.47250\n",
      "Epoch 21/50\n",
      "3200/3200 [==============================] - 57s 18ms/step - loss: 0.9478 - acc: 0.5919 - val_loss: 1.4870 - val_acc: 0.3962\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.47250\n",
      "Epoch 22/50\n",
      "3200/3200 [==============================] - 57s 18ms/step - loss: 0.9221 - acc: 0.6103 - val_loss: 1.3495 - val_acc: 0.4562\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.47250\n",
      "Epoch 23/50\n",
      "3200/3200 [==============================] - 59s 19ms/step - loss: 0.8024 - acc: 0.6478 - val_loss: 1.2718 - val_acc: 0.4888\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.47250 to 0.48875, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544163216.7849946.hdf5\n",
      "Epoch 24/50\n",
      "3200/3200 [==============================] - 58s 18ms/step - loss: 0.7526 - acc: 0.6684 - val_loss: 1.3196 - val_acc: 0.4650\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.48875\n",
      "Epoch 25/50\n",
      "3200/3200 [==============================] - 57s 18ms/step - loss: 0.7172 - acc: 0.6959 - val_loss: 1.2997 - val_acc: 0.4950\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.48875 to 0.49500, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544163216.7849946.hdf5\n",
      "Epoch 26/50\n",
      "3200/3200 [==============================] - 59s 18ms/step - loss: 0.7020 - acc: 0.6897 - val_loss: 1.3315 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.49500\n",
      "Epoch 27/50\n",
      "3200/3200 [==============================] - 57s 18ms/step - loss: 0.6693 - acc: 0.6963 - val_loss: 1.3090 - val_acc: 0.4775\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.49500\n",
      "Epoch 28/50\n",
      "3200/3200 [==============================] - 59s 18ms/step - loss: 0.6605 - acc: 0.7056 - val_loss: 1.3212 - val_acc: 0.4650\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.49500\n",
      "Epoch 29/50\n",
      "3200/3200 [==============================] - 58s 18ms/step - loss: 0.6382 - acc: 0.7222 - val_loss: 1.3679 - val_acc: 0.4688\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.49500\n",
      "Epoch 30/50\n",
      "3200/3200 [==============================] - 58s 18ms/step - loss: 0.6139 - acc: 0.7278 - val_loss: 1.3332 - val_acc: 0.4688\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.49500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train_numerical, epochs=50, batch_size=64, validation_split=0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 8s 8ms/step\n",
      "Accuracy: 49.10%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test_numerical, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 50)                70200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 71,325\n",
      "Trainable params: 71,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "rnn_layer_num_units = 50\n",
    "num_classes_for_training = len(y_train_categorical.categories)\n",
    "model = Sequential()\n",
    "model.add(LSTM(rnn_layer_num_units, input_shape=(number_of_time_stamps, number_of_features), dropout = 0.2))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(num_classes_for_training, activation='softmax'))\n",
    "# Compiling the model\n",
    "model.compile(loss= 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a checkpoint\n",
    "parent_weight_save_dir = '../../data/Training Results/LSTM/Weights'\n",
    "tensor_board_dir_path = '../../data/Training Results/LSTM/TensorBoard'\n",
    "check_output_directory(parent_weight_save_dir)\n",
    "current_experiment_name = f'AllClasses_InputVectorLen-{number_of_features}_Dense20_TimeStamps-{number_of_time_stamps}_CT-{time.time()}'\n",
    "weight_file_path = os.path.join(parent_weight_save_dir, f'{current_experiment_name}.hdf5')\n",
    "tensor_board_file_path = os.path.join(tensor_board_dir_path, current_experiment_name)\n",
    "check_output_directory(tensor_board_file_path)\n",
    "checkpoint = ModelCheckpoint(weight_file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "tensorboard = TensorBoard(log_dir=tensor_board_file_path)\n",
    "early_stopping_criteria = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "callbacks_list = [tensorboard, checkpoint, early_stopping_criteria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/50\n",
      "3200/3200 [==============================] - 30s 10ms/step - loss: 1.5821 - acc: 0.2106 - val_loss: 1.5241 - val_acc: 0.2888\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.28875, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_Dense20_TimeStamps-294_CT-1544166451.2736619.hdf5\n",
      "Epoch 2/50\n",
      "3200/3200 [==============================] - 26s 8ms/step - loss: 1.3877 - acc: 0.3794 - val_loss: 1.3512 - val_acc: 0.3600\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.28875 to 0.36000, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_Dense20_TimeStamps-294_CT-1544166451.2736619.hdf5\n",
      "Epoch 3/50\n",
      "3200/3200 [==============================] - 26s 8ms/step - loss: 1.2631 - acc: 0.3953 - val_loss: 1.2765 - val_acc: 0.3787\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.36000 to 0.37875, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_Dense20_TimeStamps-294_CT-1544166451.2736619.hdf5\n",
      "Epoch 4/50\n",
      "3200/3200 [==============================] - 28s 9ms/step - loss: 1.2270 - acc: 0.4206 - val_loss: 1.2699 - val_acc: 0.3775\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.37875\n",
      "Epoch 5/50\n",
      "3200/3200 [==============================] - 30s 9ms/step - loss: 1.2171 - acc: 0.4363 - val_loss: 1.2674 - val_acc: 0.3862\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.37875 to 0.38625, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_Dense20_TimeStamps-294_CT-1544166451.2736619.hdf5\n",
      "Epoch 6/50\n",
      "3200/3200 [==============================] - 33s 10ms/step - loss: 1.1982 - acc: 0.4406 - val_loss: 1.2801 - val_acc: 0.3812\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.38625\n",
      "Epoch 7/50\n",
      "3200/3200 [==============================] - 33s 10ms/step - loss: 1.1915 - acc: 0.4516 - val_loss: 1.2646 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.38625\n",
      "Epoch 8/50\n",
      "3200/3200 [==============================] - 33s 10ms/step - loss: 1.1475 - acc: 0.4734 - val_loss: 1.2478 - val_acc: 0.4062\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.38625 to 0.40625, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_Dense20_TimeStamps-294_CT-1544166451.2736619.hdf5\n",
      "Epoch 9/50\n",
      "3200/3200 [==============================] - 33s 10ms/step - loss: 1.1252 - acc: 0.4859 - val_loss: 1.2498 - val_acc: 0.4062\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.40625\n",
      "Epoch 10/50\n",
      "3200/3200 [==============================] - 34s 10ms/step - loss: 1.1069 - acc: 0.4913 - val_loss: 1.2436 - val_acc: 0.4275\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.40625 to 0.42750, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_Dense20_TimeStamps-294_CT-1544166451.2736619.hdf5\n",
      "Epoch 11/50\n",
      "3200/3200 [==============================] - 32s 10ms/step - loss: 1.0744 - acc: 0.5316 - val_loss: 1.2307 - val_acc: 0.4313\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.42750 to 0.43125, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_Dense20_TimeStamps-294_CT-1544166451.2736619.hdf5\n",
      "Epoch 12/50\n",
      "3200/3200 [==============================] - 33s 10ms/step - loss: 1.0556 - acc: 0.5325 - val_loss: 1.2219 - val_acc: 0.4525\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.43125 to 0.45250, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_Dense20_TimeStamps-294_CT-1544166451.2736619.hdf5\n",
      "Epoch 13/50\n",
      "3200/3200 [==============================] - 32s 10ms/step - loss: 1.0386 - acc: 0.5359 - val_loss: 1.2164 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.45250\n",
      "Epoch 14/50\n",
      "3200/3200 [==============================] - 33s 10ms/step - loss: 1.0163 - acc: 0.5481 - val_loss: 1.2517 - val_acc: 0.4562\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.45250 to 0.45625, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_Dense20_TimeStamps-294_CT-1544166451.2736619.hdf5\n",
      "Epoch 15/50\n",
      "3200/3200 [==============================] - 33s 10ms/step - loss: 0.9903 - acc: 0.5644 - val_loss: 1.2249 - val_acc: 0.4612\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.45625 to 0.46125, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_Dense20_TimeStamps-294_CT-1544166451.2736619.hdf5\n",
      "Epoch 16/50\n",
      "3200/3200 [==============================] - 33s 10ms/step - loss: 0.9675 - acc: 0.5809 - val_loss: 1.2272 - val_acc: 0.4637\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.46125 to 0.46375, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_Dense20_TimeStamps-294_CT-1544166451.2736619.hdf5\n",
      "Epoch 17/50\n",
      "3200/3200 [==============================] - 33s 10ms/step - loss: 0.9539 - acc: 0.5806 - val_loss: 1.2452 - val_acc: 0.4725\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.46375 to 0.47250, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_Dense20_TimeStamps-294_CT-1544166451.2736619.hdf5\n",
      "Epoch 18/50\n",
      "3200/3200 [==============================] - 33s 10ms/step - loss: 0.9556 - acc: 0.5853 - val_loss: 1.2401 - val_acc: 0.4725\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.47250\n",
      "Epoch 19/50\n",
      "3200/3200 [==============================] - 33s 10ms/step - loss: 0.9225 - acc: 0.5975 - val_loss: 1.2577 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.47250\n",
      "Epoch 20/50\n",
      "3200/3200 [==============================] - 33s 10ms/step - loss: 0.8932 - acc: 0.6081 - val_loss: 1.2756 - val_acc: 0.4713\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.47250\n",
      "Epoch 21/50\n",
      "3200/3200 [==============================] - 33s 10ms/step - loss: 0.8909 - acc: 0.6144 - val_loss: 1.2988 - val_acc: 0.4813\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.47250 to 0.48125, saving model to ../../data/Training Results/LSTM/Weights\\AllClasses_InputVectorLen-300_Dense20_TimeStamps-294_CT-1544166451.2736619.hdf5\n",
      "Epoch 22/50\n",
      "3200/3200 [==============================] - 33s 10ms/step - loss: 0.8617 - acc: 0.6159 - val_loss: 1.3622 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.48125\n",
      "Epoch 23/50\n",
      "3200/3200 [==============================] - 32s 10ms/step - loss: 0.9901 - acc: 0.5687 - val_loss: 1.3011 - val_acc: 0.4537\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.48125\n",
      "Epoch 24/50\n",
      "3200/3200 [==============================] - 33s 10ms/step - loss: 0.9216 - acc: 0.6022 - val_loss: 1.3158 - val_acc: 0.4525\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.48125\n",
      "Epoch 25/50\n",
      "3200/3200 [==============================] - 33s 10ms/step - loss: 0.8921 - acc: 0.6134 - val_loss: 1.3350 - val_acc: 0.4562\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.48125\n",
      "Epoch 26/50\n",
      "3200/3200 [==============================] - 33s 10ms/step - loss: 0.8558 - acc: 0.6309 - val_loss: 1.3429 - val_acc: 0.4500\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.48125\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train_numerical, epochs=50, batch_size=64, validation_split=0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s 5ms/step\n",
      "Accuracy: 46.10%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test_numerical, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
