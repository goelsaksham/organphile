{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Binary RNN Model\n",
    "\n",
    "This notebook is used to train a simple Vanilla RNN model for Binary classification of Piano and Electric Guitar. We chose the following two classes because there numbers are really close to each other, hence would be able to solve the class imbalance issue beforehand and dont have to worry about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n",
    "\n",
    "This section will import the required libaries that will be used to actually implement the training for the Vanilla RNN Binary Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saksham Goel\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, Input\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding this so that can use the python scripts for loading the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the python script training data loader function. This function loads the data from the *.wav* files directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_scripts.directory_funcs import *\n",
    "from py_scripts.wav_file_funcs import *\n",
    "from py_scripts.misc_audio_signal_funcs import *\n",
    "from py_scripts.raw_training_data_creation import load_irmas_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Training Data\n",
    "\n",
    "This section uses the script from the training data creation module to load the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cel', 'cla', 'flu', 'gac', 'gel', 'org', 'pia', 'sax', 'tru', 'vio', 'voi']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First define the training data directory, and find the different classes that exist\n",
    "training_data_dir = '../../data/whole_dataset/training/'\n",
    "get_subdirectory_names(training_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classes that we will work\n",
    "all_classes = get_subdirectory_names(training_data_dir)\n",
    "# Defining the classes that will be the ones on which we will train for the project\n",
    "classes_for_project = ['gel', 'pia', 'sax', 'vio', 'voi']\n",
    "mapping_to_index = dict(zip(classes_for_project, range(len(classes_for_project))))\n",
    "# Getting the frequency for each class\n",
    "class_num_files = dict(zip(classes_for_project, [len(get_file_names(construct_path(training_data_dir, class_name), '*.wav')) for class_name in classes_for_project]))\n",
    "# Defining the class which will be used as the one v/s all classifier to denote all other classes except the current class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Data from gel\n",
      "Processing: 300 files\n",
      "Loaded all the data from the class\n",
      "Getting Data from pia\n",
      "Processing: 300 files\n",
      "Loaded all the data from the class\n",
      "Getting Data from sax\n",
      "Processing: 300 files\n",
      "Loaded all the data from the class\n",
      "Getting Data from vio\n",
      "Processing: 300 files\n",
      "Loaded all the data from the class\n",
      "Getting Data from voi\n",
      "Processing: 300 files\n",
      "Loaded all the data from the class\n"
     ]
    }
   ],
   "source": [
    "# Defining the various parameters for loading the input data\n",
    "rnn_window = (300, 300) # in the format of length of vector and the shift\n",
    "class_num_examples = 300\n",
    "X, y = load_irmas_data(training_data_dir, classes_for_project, rnn_window, number_of_training_examples_per_class=class_num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6000, 294, 300), (6000,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying the shape\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing a train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeing up previous memory\n",
    "X = None\n",
    "y = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Training Samples: (4800,)\n",
      "Total number of timestamp values for each sample: 294\n",
      "Total number of features for each sample: 300\n"
     ]
    }
   ],
   "source": [
    "print(f'Total Number of Training Samples: {y_train.shape}')\n",
    "print(f'Total number of timestamp values for each sample: {X_train.shape[1]}')\n",
    "print(f'Total number of features for each sample: {X_train.shape[-1]}')\n",
    "#print(f'Minimum Feature Value: {np.min(X_train)}, Maximum Feature Value: {np.max(X_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Testing Samples: (1200,)\n",
      "Total number of timestamp values for each sample: 294\n",
      "Total number of features for each sample: 300\n"
     ]
    }
   ],
   "source": [
    "print(f'Total Number of Testing Samples: {y_test.shape}')\n",
    "print(f'Total number of timestamp values for each sample: {X_test.shape[1]}')\n",
    "print(f'Total number of features for each sample: {X_test.shape[-1]}')\n",
    "#print(f'Minimum Feature Value: {np.min(X_train)}, Maximum Feature Value: {np.max(X_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gel', 'pia', 'sax', 'vio', 'voi'], dtype='object') Index(['gel', 'pia', 'sax', 'vio', 'voi'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "y_train_categorical = pd.Categorical(y_train)\n",
    "y_train_numerical = y_train_categorical.codes\n",
    "y_test_categorical = pd.Categorical(y_test)\n",
    "y_test_numerical = y_test_categorical.codes\n",
    "# Checking the categries\n",
    "print(y_train_categorical.categories, y_test_categorical.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of categories\n",
    "len(y_train_categorical.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If training for more than 1 class then need to convert to categorical\n",
    "if len(y_train_categorical.categories) > 2:\n",
    "    y_train_numerical = to_categorical(y_train_numerical)\n",
    "    y_test_numerical = to_categorical(y_test_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_numerical.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check For Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('X_train', 1693440128),\n",
       " ('X_test', 423360128),\n",
       " ('y_train', 57696),\n",
       " ('y_test', 14496),\n",
       " ('y_train_categorical', 5284),\n",
       " ('y_test_categorical', 1684),\n",
       " ('Dense', 1056),\n",
       " ('EarlyStopping', 1056),\n",
       " ('Embedding', 1056),\n",
       " ('ModelCheckpoint', 1056),\n",
       " ('Sequential', 1056),\n",
       " ('SimpleRNN', 1056),\n",
       " ('TensorBoard', 1056),\n",
       " ('nb_dir', 285),\n",
       " ('class_num_files', 240),\n",
       " ('mapping_to_index', 240),\n",
       " ('all_classes', 160),\n",
       " ('training_data_dir', 153),\n",
       " ('Input', 136),\n",
       " ('check_output_directory', 136),\n",
       " ('construct_path', 136),\n",
       " ('exist_directory', 136),\n",
       " ('exist_file', 136),\n",
       " ('get_directory_contents', 136),\n",
       " ('get_file_names', 136),\n",
       " ('get_left_channel_data', 136),\n",
       " ('get_right_channel_data', 136),\n",
       " ('get_sound_signals', 136),\n",
       " ('get_subdirectory_names', 136),\n",
       " ('load_irmas_data', 136),\n",
       " ('normalize_sound_signals', 136),\n",
       " ('read_wav_file', 136),\n",
       " ('shift_sound_signals', 136),\n",
       " ('to_categorical', 136),\n",
       " ('train_test_split', 136),\n",
       " ('y_test_numerical', 112),\n",
       " ('y_train_numerical', 112),\n",
       " ('classes_for_project', 104),\n",
       " ('np', 80),\n",
       " ('pd', 80),\n",
       " ('sequence', 80),\n",
       " ('wavfile', 80),\n",
       " ('rnn_window', 64),\n",
       " ('class_num_examples', 28),\n",
       " ('X', 16),\n",
       " ('y', 16)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "This section will define the model architecture that will be used for the training purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features (Feature Vector Length): 300, Number of Time Stamps: 294\n"
     ]
    }
   ],
   "source": [
    "# Defining the parameters for the Embedding layer\n",
    "number_of_features = X_train.shape[-1]\n",
    "number_of_time_stamps = X_train.shape[1]\n",
    "print(f'Number of Features (Feature Vector Length): {number_of_features}, Number of Time Stamps: {number_of_time_stamps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_8 (SimpleRNN)     (None, 50)                17550     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 17,805\n",
      "Trainable params: 17,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "rnn_layer_num_units = 50\n",
    "num_classes_for_training = len(y_train_categorical.categories)\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(rnn_layer_num_units, input_shape=(number_of_time_stamps, number_of_features), dropout = 0.1))\n",
    "model.add(Dense(num_classes_for_training, activation='softmax'))\n",
    "# Compiling the model\n",
    "model.compile(loss= 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a checkpoint\n",
    "parent_weight_save_dir = '../../data/Training Results/Vanilla Simple RNN/Weights'\n",
    "tensor_board_dir_path = '../../data/Training Results/Vanilla Simple RNN/TensorBoard'\n",
    "check_output_directory(parent_weight_save_dir)\n",
    "current_experiment_name = f'AllClasses_InputVectorLen-{number_of_features}_TimeStamps-{number_of_time_stamps}_CT-{time.time()}'\n",
    "weight_file_path = os.path.join(parent_weight_save_dir, f'{current_experiment_name}.hdf5')\n",
    "tensor_board_file_path = os.path.join(tensor_board_dir_path, current_experiment_name)\n",
    "check_output_directory(tensor_board_file_path)\n",
    "checkpoint = ModelCheckpoint(weight_file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "tensorboard = TensorBoard(log_dir=tensor_board_file_path)\n",
    "early_stopping_criteria = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "callbacks_list = [tensorboard, checkpoint, early_stopping_criteria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3840 samples, validate on 960 samples\n",
      "Epoch 1/50\n",
      "3840/3840 [==============================] - 14s 4ms/step - loss: 1.5908 - acc: 0.2602 - val_loss: 1.5387 - val_acc: 0.2979\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.29792, saving model to ../../data/Training Results/Vanilla Simple RNN/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544152149.7949927.hdf5\n",
      "Epoch 2/50\n",
      "3840/3840 [==============================] - 17s 4ms/step - loss: 1.5378 - acc: 0.3081 - val_loss: 1.5635 - val_acc: 0.3177\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.29792 to 0.31771, saving model to ../../data/Training Results/Vanilla Simple RNN/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544152149.7949927.hdf5\n",
      "Epoch 3/50\n",
      "3840/3840 [==============================] - 16s 4ms/step - loss: 1.4372 - acc: 0.3576 - val_loss: 1.5245 - val_acc: 0.3010\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.31771\n",
      "Epoch 4/50\n",
      "3840/3840 [==============================] - 17s 4ms/step - loss: 1.4226 - acc: 0.3753 - val_loss: 1.4947 - val_acc: 0.3250\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.31771 to 0.32500, saving model to ../../data/Training Results/Vanilla Simple RNN/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544152149.7949927.hdf5\n",
      "Epoch 5/50\n",
      "3840/3840 [==============================] - 15s 4ms/step - loss: 1.3575 - acc: 0.4099 - val_loss: 1.5163 - val_acc: 0.3365\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.32500 to 0.33646, saving model to ../../data/Training Results/Vanilla Simple RNN/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544152149.7949927.hdf5\n",
      "Epoch 6/50\n",
      "3840/3840 [==============================] - 16s 4ms/step - loss: 1.4749 - acc: 0.3721 - val_loss: 1.5699 - val_acc: 0.2604\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.33646\n",
      "Epoch 7/50\n",
      "3840/3840 [==============================] - 16s 4ms/step - loss: 1.5074 - acc: 0.3307 - val_loss: 1.5447 - val_acc: 0.2938\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.33646\n",
      "Epoch 8/50\n",
      "3840/3840 [==============================] - 17s 4ms/step - loss: 1.3580 - acc: 0.4117 - val_loss: 1.4556 - val_acc: 0.3406\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.33646 to 0.34063, saving model to ../../data/Training Results/Vanilla Simple RNN/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544152149.7949927.hdf5\n",
      "Epoch 9/50\n",
      "3840/3840 [==============================] - 16s 4ms/step - loss: 1.2889 - acc: 0.4521 - val_loss: 1.4247 - val_acc: 0.3521\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.34063 to 0.35208, saving model to ../../data/Training Results/Vanilla Simple RNN/Weights\\AllClasses_InputVectorLen-300_TimeStamps-294_CT-1544152149.7949927.hdf5\n",
      "Epoch 10/50\n",
      "3840/3840 [==============================] - 17s 5ms/step - loss: 1.3317 - acc: 0.4354 - val_loss: 1.5067 - val_acc: 0.3292\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.35208\n",
      "Epoch 11/50\n",
      "3840/3840 [==============================] - 16s 4ms/step - loss: 1.4558 - acc: 0.3740 - val_loss: 1.6368 - val_acc: 0.2573\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.35208\n",
      "Epoch 12/50\n",
      "3840/3840 [==============================] - 16s 4ms/step - loss: 1.3882 - acc: 0.4076 - val_loss: 1.6062 - val_acc: 0.2990\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.35208\n",
      "Epoch 13/50\n",
      "3840/3840 [==============================] - 16s 4ms/step - loss: 1.3490 - acc: 0.4221 - val_loss: 1.5536 - val_acc: 0.3208\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.35208\n",
      "Epoch 14/50\n",
      "3840/3840 [==============================] - 16s 4ms/step - loss: 1.2872 - acc: 0.4539 - val_loss: 1.5089 - val_acc: 0.3469\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.35208\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train_numerical, epochs=50, batch_size=64, validation_split=0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 3s 3ms/step\n",
      "Accuracy: 36.25%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test_numerical, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model Initialization with different layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_17 (SimpleRNN)    (None, 75)                28200     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 30)                2280      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 31,205\n",
      "Trainable params: 31,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "rnn_layer_num_units = 75\n",
    "num_classes_for_training = len(y_train_categorical.categories)\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(rnn_layer_num_units, input_shape=(number_of_time_stamps, number_of_features), dropout = 0.1))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(num_classes_for_training, activation='softmax'))\n",
    "# Compiling the model\n",
    "model.compile(loss= 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a checkpoint\n",
    "parent_weight_save_dir = '../../data/Training Results/Vanilla Simple RNN/Weights'\n",
    "tensor_board_dir_path = '../../data/Training Results/Vanilla Simple RNN/TensorBoard'\n",
    "check_output_directory(parent_weight_save_dir)\n",
    "current_experiment_name = f'AllClasses_HiddenUnits-{rnn_layer_num_units}_InputVectorLen-{number_of_features}_TimeStamps-{number_of_time_stamps}_CT-{time.time()}'\n",
    "weight_file_path = os.path.join(parent_weight_save_dir, f'{current_experiment_name}.hdf5')\n",
    "tensor_board_file_path = os.path.join(tensor_board_dir_path, current_experiment_name)\n",
    "check_output_directory(tensor_board_file_path)\n",
    "checkpoint = ModelCheckpoint(weight_file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "tensorboard = TensorBoard(log_dir=tensor_board_file_path)\n",
    "early_stopping_criteria = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "callbacks_list = [tensorboard, checkpoint, early_stopping_criteria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3840 samples, validate on 960 samples\n",
      "Epoch 1/50\n",
      "3840/3840 [==============================] - 23s 6ms/step - loss: 1.5529 - acc: 0.2750 - val_loss: 1.5423 - val_acc: 0.2573\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.25729, saving model to ../../data/Training Results/Vanilla Simple RNN/Weights\\AllClasses_HiddenUnits-75_InputVectorLen-300_TimeStamps-294_CT-1544159872.6018162.hdf5\n",
      "Epoch 2/50\n",
      "3840/3840 [==============================] - 22s 6ms/step - loss: 1.3936 - acc: 0.3544 - val_loss: 1.4241 - val_acc: 0.2938\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.25729 to 0.29375, saving model to ../../data/Training Results/Vanilla Simple RNN/Weights\\AllClasses_HiddenUnits-75_InputVectorLen-300_TimeStamps-294_CT-1544159872.6018162.hdf5\n",
      "Epoch 3/50\n",
      "3840/3840 [==============================] - 22s 6ms/step - loss: 1.2778 - acc: 0.4008 - val_loss: 1.3953 - val_acc: 0.3365\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.29375 to 0.33646, saving model to ../../data/Training Results/Vanilla Simple RNN/Weights\\AllClasses_HiddenUnits-75_InputVectorLen-300_TimeStamps-294_CT-1544159872.6018162.hdf5\n",
      "Epoch 4/50\n",
      "3840/3840 [==============================] - 22s 6ms/step - loss: 1.3399 - acc: 0.3932 - val_loss: 1.4209 - val_acc: 0.3292\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.33646\n",
      "Epoch 5/50\n",
      "3840/3840 [==============================] - 22s 6ms/step - loss: 1.2349 - acc: 0.4245 - val_loss: 1.4057 - val_acc: 0.3344\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.33646\n",
      "Epoch 6/50\n",
      "3840/3840 [==============================] - 22s 6ms/step - loss: 1.2497 - acc: 0.4294 - val_loss: 1.4036 - val_acc: 0.3490\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.33646 to 0.34896, saving model to ../../data/Training Results/Vanilla Simple RNN/Weights\\AllClasses_HiddenUnits-75_InputVectorLen-300_TimeStamps-294_CT-1544159872.6018162.hdf5\n",
      "Epoch 7/50\n",
      "3840/3840 [==============================] - 22s 6ms/step - loss: 1.2088 - acc: 0.4510 - val_loss: 1.3784 - val_acc: 0.3677\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.34896 to 0.36771, saving model to ../../data/Training Results/Vanilla Simple RNN/Weights\\AllClasses_HiddenUnits-75_InputVectorLen-300_TimeStamps-294_CT-1544159872.6018162.hdf5\n",
      "Epoch 8/50\n",
      "3840/3840 [==============================] - 22s 6ms/step - loss: 1.1757 - acc: 0.4724 - val_loss: 1.3749 - val_acc: 0.3573\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.36771\n",
      "Epoch 9/50\n",
      "3840/3840 [==============================] - 22s 6ms/step - loss: 1.1573 - acc: 0.4719 - val_loss: 1.3679 - val_acc: 0.3615\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.36771\n",
      "Epoch 10/50\n",
      "3840/3840 [==============================] - 22s 6ms/step - loss: 1.1286 - acc: 0.4846 - val_loss: 1.3751 - val_acc: 0.3729\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.36771 to 0.37292, saving model to ../../data/Training Results/Vanilla Simple RNN/Weights\\AllClasses_HiddenUnits-75_InputVectorLen-300_TimeStamps-294_CT-1544159872.6018162.hdf5\n",
      "Epoch 11/50\n",
      "3840/3840 [==============================] - 21s 5ms/step - loss: 1.1183 - acc: 0.4961 - val_loss: 1.4172 - val_acc: 0.3552\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.37292\n",
      "Epoch 12/50\n",
      "3840/3840 [==============================] - 21s 5ms/step - loss: 1.1449 - acc: 0.4792 - val_loss: 1.4253 - val_acc: 0.3719\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.37292\n",
      "Epoch 13/50\n",
      "3840/3840 [==============================] - 23s 6ms/step - loss: 1.1106 - acc: 0.5003 - val_loss: 1.4037 - val_acc: 0.3802\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.37292 to 0.38021, saving model to ../../data/Training Results/Vanilla Simple RNN/Weights\\AllClasses_HiddenUnits-75_InputVectorLen-300_TimeStamps-294_CT-1544159872.6018162.hdf5\n",
      "Epoch 14/50\n",
      "3840/3840 [==============================] - 22s 6ms/step - loss: 1.0786 - acc: 0.5130 - val_loss: 1.3979 - val_acc: 0.3979\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.38021 to 0.39792, saving model to ../../data/Training Results/Vanilla Simple RNN/Weights\\AllClasses_HiddenUnits-75_InputVectorLen-300_TimeStamps-294_CT-1544159872.6018162.hdf5\n",
      "Epoch 15/50\n",
      "3840/3840 [==============================] - 24s 6ms/step - loss: 1.0832 - acc: 0.5073 - val_loss: 1.3877 - val_acc: 0.3979\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.39792\n",
      "Epoch 16/50\n",
      "3840/3840 [==============================] - 23s 6ms/step - loss: 1.3450 - acc: 0.4414 - val_loss: 1.4638 - val_acc: 0.3510\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.39792\n",
      "Epoch 17/50\n",
      "3840/3840 [==============================] - 25s 6ms/step - loss: 1.1928 - acc: 0.4633 - val_loss: 1.4315 - val_acc: 0.3490\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.39792\n",
      "Epoch 18/50\n",
      "3840/3840 [==============================] - 22s 6ms/step - loss: 1.1634 - acc: 0.4724 - val_loss: 1.4368 - val_acc: 0.3812\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.39792\n",
      "Epoch 19/50\n",
      "3840/3840 [==============================] - 22s 6ms/step - loss: 1.1138 - acc: 0.5034 - val_loss: 1.4334 - val_acc: 0.3854\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.39792\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train_numerical, epochs=50, batch_size=64, validation_split=0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 6s 5ms/step\n",
      "Accuracy: 37.67%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test_numerical, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
