{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN MRP Model\n",
    "\n",
    "This notebook is used to train a CNN model for All class classification on top of the stacking images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n",
    "\n",
    "This section will import the required libaries that will be used to actually implement the training for the Vanilla RNN Binary Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saksham Goel\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, BatchNormalization, Flatten, Dense\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding this so that can use the python scripts for loading the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the python script training data loader function. This function loads the data from the *.wav* files directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_scripts.directory_funcs import *\n",
    "from py_scripts.wav_file_funcs import *\n",
    "from py_scripts.misc_audio_signal_funcs import *\n",
    "from py_scripts.raw_training_data_creation import load_irmas_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Training Data\n",
    "\n",
    "This section defines the training data generators the script from the training data creation module to load the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gel', 'pia', 'sax', 'vio', 'voi']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First define the training data directory, and find the different classes that exist\n",
    "training_data_dir = '../../data/mrp_jpg/train/'\n",
    "validation_data_dir = '../../data/mrp_jpg/validation/'\n",
    "test_data_dir = '../../data/mrp_jpg/test/'\n",
    "get_subdirectory_names(training_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the generators for each category (Train, Validation, Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1493 images belonging to 5 classes.\n",
      "Found 318 images belonging to 5 classes.\n",
      "Found 318 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('../../data/mrp_jpg/train/', target_size=(150, 150),\n",
    "                                                    batch_size=64, class_mode='categorical')\n",
    "validaton_generator = validation_datagen.flow_from_directory('../../data/mrp_jpg/validation/', target_size=(150, 150),\n",
    "                                                             batch_size=64, class_mode='categorical')\n",
    "test_generator = test_datagen.flow_from_directory('../../data/mrp_jpg/test/', target_size=(150, 150),\n",
    "                                                  batch_size=64, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Model\n",
    "\n",
    "In this section, we define the CNN model for the stacked images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 73, 73, 16)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 36, 36, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 34, 34, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 15, 15, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 5, 5, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 24,997\n",
      "Trainable params: 24,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (5, 5), strides=(2, 2), activation='relu', input_shape = (150, 150, 3)))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), strides = (1, 1), activation='relu'))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), strides = (1, 1), activation='relu'))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), strides = (1, 1), activation='relu'))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(5, activation = 'softmax'))\n",
    "# Compiling the model\n",
    "model.compile(loss= 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a checkpoint\n",
    "parent_weight_save_dir = '../../data/Training Results/CNN_MRP/Weights'\n",
    "tensor_board_dir_path = '../../data/Training Results/CNN_MRP/TensorBoard'\n",
    "check_output_directory(parent_weight_save_dir)\n",
    "current_experiment_name = f'CT-{time.time()}'\n",
    "weight_file_path = os.path.join(parent_weight_save_dir, f'{current_experiment_name}.hdf5')\n",
    "tensor_board_file_path = os.path.join(tensor_board_dir_path, current_experiment_name)\n",
    "check_output_directory(tensor_board_file_path)\n",
    "checkpoint = ModelCheckpoint(weight_file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "tensorboard = TensorBoard(log_dir=tensor_board_file_path)\n",
    "early_stopping_criteria = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "callbacks_list = [tensorboard, checkpoint, early_stopping_criteria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "24/24 [==============================] - 26s 1s/step - loss: 1.4823 - acc: 0.3205 - val_loss: 1.3793 - val_acc: 0.3365\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.33648, saving model to ../../data/Training Results/CNN_MRP/Weights\\CT-1544943488.2030275.hdf5\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 31s 1s/step - loss: 1.4032 - acc: 0.4137 - val_loss: 1.3238 - val_acc: 0.4403\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.33648 to 0.44025, saving model to ../../data/Training Results/CNN_MRP/Weights\\CT-1544943488.2030275.hdf5\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 25s 1s/step - loss: 1.3600 - acc: 0.4424 - val_loss: 1.2977 - val_acc: 0.4969\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.44025 to 0.49686, saving model to ../../data/Training Results/CNN_MRP/Weights\\CT-1544943488.2030275.hdf5\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 24s 1s/step - loss: 1.2770 - acc: 0.4475 - val_loss: 1.1621 - val_acc: 0.4969\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.49686\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 33s 1s/step - loss: 1.2262 - acc: 0.4546 - val_loss: 1.1458 - val_acc: 0.4843\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.49686\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 30s 1s/step - loss: 1.2098 - acc: 0.4529 - val_loss: 1.1377 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.49686 to 0.50000, saving model to ../../data/Training Results/CNN_MRP/Weights\\CT-1544943488.2030275.hdf5\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 24s 983ms/step - loss: 1.1899 - acc: 0.4580 - val_loss: 1.1344 - val_acc: 0.4969\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.50000\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 24s 1s/step - loss: 1.2002 - acc: 0.4684 - val_loss: 1.1175 - val_acc: 0.4937\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.50000\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 24s 1s/step - loss: 1.1970 - acc: 0.4508 - val_loss: 1.1485 - val_acc: 0.4937\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.50000\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 23s 975ms/step - loss: 1.1674 - acc: 0.4684 - val_loss: 1.1154 - val_acc: 0.4623\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.50000\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 25s 1s/step - loss: 1.1662 - acc: 0.4744 - val_loss: 1.1061 - val_acc: 0.4906\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.50000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator, epochs=50, validation_data=validaton_generator, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
