{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Binary RNN Model\n",
    "\n",
    "This notebook is used to train a simple Vanilla RNN model for Binary classification of Piano and Electric Guitar. We chose the following two classes because there numbers are really close to each other, hence would be able to solve the class imbalance issue beforehand and dont have to worry about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n",
    "\n",
    "This section will import the required libaries that will be used to actually implement the training for the Vanilla RNN Binary Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_scripts.raw_training_data_creation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saksham Goel\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, Input\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data Creator\n",
    "\n",
    "This section uses the script from the training data creation module to load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from scipy.io import wavfile\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def exist_directory(directory_path: str):\n",
    "    return os.path.isdir(directory_path)\n",
    "\n",
    "\n",
    "def exist_file(file_path: str):\n",
    "    return os.path.isfile(file_path)\n",
    "\n",
    "\n",
    "def get_directory_contents(directory_path: str, pattern: str):\n",
    "    if exist_directory(directory_path):\n",
    "        # Get the current working directory\n",
    "        cwd = os.getcwd()\n",
    "        # Change the directory into the target directory path\n",
    "        os.chdir(directory_path)\n",
    "        # Get the list of directory contents\n",
    "        directory_contents = glob.glob(pattern)\n",
    "        # Change back to the original process working directory\n",
    "        os.chdir(cwd)\n",
    "        # Return back the directory contents\n",
    "        return directory_contents\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "\n",
    "def get_subdirectory_names(directory_path: str):\n",
    "    return list(map(lambda subdirectory_name: subdirectory_name.replace('\\\\', '').replace('//', ''),\n",
    "                    get_directory_contents(directory_path, '*//')))\n",
    "\n",
    "\n",
    "def get_file_names(directory_path: str, file_extension: str):\n",
    "    return get_directory_contents(directory_path, f'*{file_extension}')\n",
    "\n",
    "\n",
    "def construct_path(directory_path: str, directory_content_name: str):\n",
    "    return os.path.join(directory_path, directory_content_name)\n",
    "\n",
    "\n",
    "def read_wav_file(file_path: str):\n",
    "    if exist_file(file_path):\n",
    "        return wavfile.read(file_path)\n",
    "    else:\n",
    "        return 44100, np.array([])\n",
    "    \n",
    "\n",
    "def get_sound_signals(wav_file_data):\n",
    "    return wav_file_data[-1]\n",
    "\n",
    "\n",
    "def shift_sound_signals(sound_signals: np.array):\n",
    "    return np.int32(sound_signals + 2**15)\n",
    "\n",
    "\n",
    "def normalize_sound_signals(sound_signals: np.array):\n",
    "    return np.float32(sound_signals / (2. ** 15))\n",
    "\n",
    "\n",
    "def get_left_channel_data(sound_signals: np.array):\n",
    "    return sound_signals[:, 0]\n",
    "\n",
    "\n",
    "def get_right_channel_data(sound_signals: np.array):\n",
    "    return sound_signals[:, -1]\n",
    "\n",
    "\n",
    "def get_sound_feature_vectors_from_file(file_path: str, normalize: bool = True, shift: bool = False):\n",
    "    if normalize:\n",
    "        sound_signals = normalize_sound_signals(get_sound_signals(read_wav_file(file_path)))\n",
    "    else:\n",
    "        sound_signals = get_sound_signals(read_wav_file(file_path))\n",
    "        if shift:\n",
    "            sound_signals = shift_sound_signals(sound_signals)\n",
    "    left_channel_feature_vector, right_channel_feature_vector = \\\n",
    "        get_left_channel_data(sound_signals), get_right_channel_data(sound_signals)\n",
    "    return left_channel_feature_vector, right_channel_feature_vector\n",
    "\n",
    "\n",
    "def stack_data(feature_matrix: np.array, left_channel_features: np.array, right_channel_features: np.array):\n",
    "    if len(feature_matrix) == 0:\n",
    "        return np.stack((left_channel_features, right_channel_features))\n",
    "    else:\n",
    "        return np.vstack((feature_matrix, left_channel_features, right_channel_features))\n",
    "\n",
    "\n",
    "def get_class_data(parent_directory_path: str, class_label: str, number_of_examples: int = 0,\n",
    "                   normalize: bool = True, shift: bool = False):\n",
    "    # Initializing the class feature matrix and target vector\n",
    "    class_feature_matrix = []\n",
    "    class_target_vector = []\n",
    "    # Construct the path\n",
    "    class_directory_path = construct_path(parent_directory_path, class_label)\n",
    "    # Make sure the given path is correct\n",
    "    if not exist_directory(class_directory_path):\n",
    "        return np.array(class_feature_matrix), np.array(class_target_vector)\n",
    "    \n",
    "    # Get the names of the wav file belonging to the current class\n",
    "    wav_file_names = set(get_file_names(class_directory_path, '.wav'))\n",
    "    # Get the subset of the classes, if want only limited number of training examples\n",
    "    if number_of_examples:\n",
    "        wav_file_names = wav_file_names[:np.abs(number_of_examples)]\n",
    "    print(f'Processing: {len(wav_file_names)} files')\n",
    "    # Iterate through each wav file\n",
    "    for file_name in wav_file_names:\n",
    "        file_path = construct_path(class_directory_path, file_name)\n",
    "        left_channel_features, right_channel_features = \\\n",
    "            get_sound_feature_vectors_from_file(file_path, normalize, shift)\n",
    "        #class_feature_matrix += [left_channel_features[:44100], right_channel_features[:44100]]\n",
    "        class_feature_matrix += [left_channel_features[:88200], right_channel_features[:88200]]\n",
    "        class_target_vector += [class_label]*2\n",
    "        \n",
    "    return np.array(class_feature_matrix), np.array(class_target_vector)\n",
    "\n",
    "\n",
    "def load_irmas_data(parent_directory_path: str, class_labels_to_process: List[str], \n",
    "                    number_of_training_examples_per_class: int = 0, normalize: bool = True,\n",
    "                    shift: bool = False):\n",
    "    if not exist_directory(parent_directory_path):\n",
    "        print(f'Invalid directory: {parent_directory_path}')\n",
    "    \n",
    "    class_labels = class_labels_to_process if class_labels_to_process else get_subdirectory_names(parent_directory_path)\n",
    "    \n",
    "    feature_matrix = np.array([])\n",
    "    target_vector = np.array([])\n",
    "    \n",
    "    for class_label in class_labels:\n",
    "        print(f'Getting Data from {class_label}')\n",
    "        class_feature_matrix, class_target_vector = get_class_data(parent_directory_path, class_label, \n",
    "                                                                   number_of_training_examples_per_class, normalize,\n",
    "                                                                   shift)\n",
    "        print(f'Loaded all the data from the class')\n",
    "        if feature_matrix.size:\n",
    "            feature_matrix = np.vstack((feature_matrix, class_feature_matrix))\n",
    "            target_vector = np.hstack((target_vector, class_target_vector))\n",
    "        else:\n",
    "            feature_matrix = class_feature_matrix\n",
    "            target_vector = class_target_vector\n",
    "    \n",
    "    return feature_matrix, target_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Data from pia\n",
      "Processing: 721 files\n",
      "Loaded all the data from the class\n",
      "Getting Data from gac\n",
      "Processing: 637 files\n",
      "Loaded all the data from the class\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_irmas_data(f'../../data/whole_dataset/training/', \n",
    "                                   ['pia', 'gac'], normalize = True, shift = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Training Samples: (2716,)\n",
      "Total number of features for each sample: 88200\n",
      "Minimum Feature Value: -1.0, Maximum Feature Value: 0.999969482421875\n"
     ]
    }
   ],
   "source": [
    "print(f'Total Number of Training Samples: {y_train.shape}')\n",
    "print(f'Total number of features for each sample: {X_train.shape[-1]}')\n",
    "print(f'Minimum Feature Value: {np.min(X_train)}, Maximum Feature Value: {np.max(X_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_categorical = pd.Categorical(y_train)\n",
    "y_train_numerical = y_train_categorical.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition\n",
    "\n",
    "This section will define the model architecture that will be used for the training purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the parameters for the Embedding layer\n",
    "number_of_features = 441\n",
    "embedding_vector_length = 10\n",
    "highest_val = np.max(X_train)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reshaped = X_train.reshape((2716, 126, 700))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 50)                17550     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 17,601\n",
      "Trainable params: 17,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(50, input_shape=(147,300), dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2716/2716 [==============================] - 4s 2ms/step - loss: 0.7024 - acc: 0.5221\n",
      "Epoch 2/20\n",
      "2716/2716 [==============================] - 4s 1ms/step - loss: 0.6716 - acc: 0.5924\n",
      "Epoch 3/20\n",
      "2716/2716 [==============================] - 4s 1ms/step - loss: 0.6642 - acc: 0.5946\n",
      "Epoch 4/20\n",
      "2716/2716 [==============================] - 4s 1ms/step - loss: 0.6506 - acc: 0.6197\n",
      "Epoch 5/20\n",
      "2716/2716 [==============================] - 4s 1ms/step - loss: 0.6458 - acc: 0.6230\n",
      "Epoch 6/20\n",
      "2716/2716 [==============================] - 4s 1ms/step - loss: 0.6335 - acc: 0.6432\n",
      "Epoch 7/20\n",
      "2716/2716 [==============================] - 4s 1ms/step - loss: 0.6492 - acc: 0.6156\n",
      "Epoch 8/20\n",
      "2716/2716 [==============================] - 4s 1ms/step - loss: 0.6277 - acc: 0.6451\n",
      "Epoch 9/20\n",
      "2716/2716 [==============================] - 4s 1ms/step - loss: 0.6133 - acc: 0.6701\n",
      "Epoch 10/20\n",
      "2716/2716 [==============================] - 4s 2ms/step - loss: 0.6152 - acc: 0.6587\n",
      "Epoch 11/20\n",
      "2716/2716 [==============================] - 4s 1ms/step - loss: 0.6015 - acc: 0.6649\n",
      "Epoch 12/20\n",
      "2716/2716 [==============================] - 4s 1ms/step - loss: 0.5905 - acc: 0.6767\n",
      "Epoch 13/20\n",
      "2716/2716 [==============================] - 4s 2ms/step - loss: 0.5835 - acc: 0.6904\n",
      "Epoch 14/20\n",
      "2716/2716 [==============================] - 4s 1ms/step - loss: 0.5622 - acc: 0.7117\n",
      "Epoch 15/20\n",
      "2716/2716 [==============================] - 4s 2ms/step - loss: 0.5732 - acc: 0.7077\n",
      "Epoch 16/20\n",
      "2716/2716 [==============================] - 4s 2ms/step - loss: 0.5564 - acc: 0.7066\n",
      "Epoch 17/20\n",
      "2716/2716 [==============================] - 4s 2ms/step - loss: 0.5646 - acc: 0.7088\n",
      "Epoch 18/20\n",
      "2716/2716 [==============================] - 4s 2ms/step - loss: 0.5464 - acc: 0.7161\n",
      "Epoch 19/20\n",
      "2716/2716 [==============================] - 4s 2ms/step - loss: 0.5381 - acc: 0.7235A: 0s - loss: 0.5355 - acc: 0.7\n",
      "Epoch 20/20\n",
      "2716/2716 [==============================] - 5s 2ms/step - loss: 0.5171 - acc: 0.7541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c32b9b6978>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_reshaped, y_train_numerical, epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2716/2716 [==============================] - 3s 1ms/step\n",
      "Accuracy: 77.47%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_train_reshaped, y_train_numerical, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Trained with More Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (None, 50)                37550     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 37,601\n",
      "Trainable params: 37,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(50, input_shape=(126,700), dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2716/2716 [==============================] - 7s 3ms/step - loss: 0.6921 - acc: 0.5486\n",
      "Epoch 2/20\n",
      "2716/2716 [==============================] - 6s 2ms/step - loss: 0.6416 - acc: 0.6395\n",
      "Epoch 3/20\n",
      "2716/2716 [==============================] - 6s 2ms/step - loss: 0.6193 - acc: 0.6513\n",
      "Epoch 4/20\n",
      "2716/2716 [==============================] - 6s 2ms/step - loss: 0.5896 - acc: 0.6874\n",
      "Epoch 5/20\n",
      "2716/2716 [==============================] - 6s 2ms/step - loss: 0.5615 - acc: 0.7187\n",
      "Epoch 6/20\n",
      "2716/2716 [==============================] - 6s 2ms/step - loss: 0.5573 - acc: 0.7139\n",
      "Epoch 7/20\n",
      "2716/2716 [==============================] - 6s 2ms/step - loss: 0.5211 - acc: 0.7496\n",
      "Epoch 8/20\n",
      "2716/2716 [==============================] - 6s 2ms/step - loss: 0.4711 - acc: 0.7813\n",
      "Epoch 9/20\n",
      "2716/2716 [==============================] - 6s 2ms/step - loss: 0.4619 - acc: 0.7732\n",
      "Epoch 10/20\n",
      "2716/2716 [==============================] - 7s 2ms/step - loss: 0.4495 - acc: 0.7898\n",
      "Epoch 11/20\n",
      "2716/2716 [==============================] - 7s 2ms/step - loss: 0.4380 - acc: 0.7997\n",
      "Epoch 12/20\n",
      "2716/2716 [==============================] - 7s 2ms/step - loss: 0.4095 - acc: 0.8019\n",
      "Epoch 13/20\n",
      "2716/2716 [==============================] - 7s 2ms/step - loss: 0.3974 - acc: 0.8155\n",
      "Epoch 14/20\n",
      "2716/2716 [==============================] - 7s 2ms/step - loss: 0.4570 - acc: 0.7916\n",
      "Epoch 15/20\n",
      "2716/2716 [==============================] - 7s 3ms/step - loss: 0.4283 - acc: 0.7990\n",
      "Epoch 16/20\n",
      "2716/2716 [==============================] - 7s 3ms/step - loss: 0.3820 - acc: 0.8299\n",
      "Epoch 17/20\n",
      "2716/2716 [==============================] - 7s 3ms/step - loss: 0.3814 - acc: 0.8406\n",
      "Epoch 18/20\n",
      "2716/2716 [==============================] - 7s 3ms/step - loss: 0.4039 - acc: 0.8251\n",
      "Epoch 19/20\n",
      "2716/2716 [==============================] - 8s 3ms/step - loss: 0.4090 - acc: 0.8181\n",
      "Epoch 20/20\n",
      "2716/2716 [==============================] - 7s 3ms/step - loss: 0.3658 - acc: 0.8443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c34a14bc50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_reshaped, y_train_numerical, epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2716/2716 [==============================] - 6s 2ms/step\n",
      "Accuracy: 86.16%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_train_reshaped, y_train_numerical, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
